{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install onnx onnxruntime\n",
    "#pip install onnx\n",
    "#!pip install onnx onnxruntime onnxruntime-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "X_scaler = joblib.load('data/scalers/X_scaler.save')\n",
    "y_scaler = joblib.load('data/scalers/y_scaler.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "expert_agent = pd.read_csv(\"data/data_generation_mpc_110_190_6_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = expert_agent[[\"inflow\", \"height\"]]\n",
    "y = expert_agent[[\"speed1_rpm\", \"speed4_rpm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X_scaler.transform(X)\n",
    "y_scaled = y_scaler.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "\n",
    "torch_dataset = TensorDataset(torch.tensor(X_scaled, dtype=torch.float32), \n",
    "                              torch.tensor(y_scaled, dtype=torch.float32))\n",
    "\n",
    "dataset_loader = DataLoader(torch_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your model takes input of the same shape as X_scaled\n",
    "# Fetch a batch of data from the DataLoader\n",
    "batch = next(iter(dataset_loader))\n",
    "\n",
    "# The first part of the batch is your inputs (features)\n",
    "dummy_input = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# Replace 'path_to_your_model.onnx' with the path to your ONNX model file\n",
    "session = onnxruntime.InferenceSession('data/models/simple_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_0\n"
     ]
    }
   ],
   "source": [
    "# Load your ONNX model\n",
    "onnx_model = onnx.load('data/models/simple_model.onnx')\n",
    "\n",
    "# Print input names\n",
    "for input in onnx_model.graph.input:\n",
    "    print(input.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {'onnx::Gemm_0': dummy_input.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = session.run(None, input_data)[0]\n",
    "\n",
    "pump1_rpm_hat, pump4_rpm_hat = yhat[:, 0], yhat[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = y_scaler.inverse_transform(batch[1].cpu())\n",
    "\n",
    "pump1_rpm_opt, pump4_rpm_opt = y_original[:,0], y_original[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
